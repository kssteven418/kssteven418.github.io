<!doctype html>
<html>

<head>
  <!--<meta name="google-site-verification" content="-7Nk1zZNdUpUv3uY4z2NdOnsrV0IaNwzgVfoPZtGYvg" />-->
  <meta name="google-site-verification" content="tJrbM3Uji0UXppLjVTvNHyTlh_L4u_mUV3ysGOWN2Gg" />
  <title>Sehoon Kim</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="index, follow" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
  <style>
    .center {
      display: flex;
      align-items: center;
      justify-content: center;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!-------------------------------------------------------------------------------------------->
        <!--Start Intro-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" src="img/main.jpg" width="200" height="257" style="object-fit: contain;">
          </div>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Sehoon Kim</h2>
            <p class="text text-medium">
              Ph.D. Candidate in
              <a target="_blank" href="https://bair.berkeley.edu/">BAIR</a>
              at <a target="_blank" href="https://eecs.berkeley.edu/">UC Berkeley</a><br>
              <b>Contact:</b> sehoonkim at berkeley dot edu <br>
              <b>CV:</b> <a target="_blank" href="files/CV_sehoonkim.pdf">link</a> (latest update: Apr. 2024)<br>
              <b>Advisor:</b> Prof. <a target="_blank" href="http://people.eecs.berkeley.edu/~keutzer/">Kurt Keutzer</a><br>
              <b>Research Interests:</b>
              Efficient AI, HW-SW Codesign, AI Systems<br>
            </p>

            </p>
          </div>
        </div>
        </div>
        <!--End Intro-->
        <!-------------------------------------------------------------------------------------------->
        <!--Start About-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">About</h2>
            <hr>
            <p class="text">
            I am a 4th year Ph.D. student in
             <a target="_blank" href="https://bair.berkeley.edu/">Berkeley AI Research (BAIR)</a>
             at  <a target="_blank" href="https://eecs.berkeley.edu/">EECS, UC Berkeley</a>.
            My research spans a <b>full-stack approach to designing efficient and privacy-preserving AI solutions</b> under the supervision of Prof.
            <a target="_blank" href="http://people.eecs.berkeley.edu/~keutzer/">Kurt Keutzer</a>.
            More specifically, my research interests lie in:
            <ul style="margin : 0; padding-top:0; margin-bottom:0;">
              <li>Efficient and hardware-aware model architectures</li>
              <li>Model compression and optimization techniques for low-cost inference (e.g. quantization and pruning)</li>
              <li>Algorithms and systems for efficient model training and inference</li>
              <li>Hardware-software co-design and co-optimization</li>
            </ul>
            </p>

            <p class="text" style="margin : 0; padding-top:0;">
            Before joining UC Berkeley, I was an undergrad majoring in
            <a target="_blank" href="https://ee.snu.ac.kr/en">Electrical and Computer Engineering (ECE)</a> at
            <a target="_blank" href="https://en.snu.ac.kr/">Seoul National University</a>,
            where I was ranked <b>1st in the entire class</b> of 2020 (overall GPA: 4.29/4.30, major GPA: 4.30/4.30).
            In my undergrad years, I was honored to work with Prof.
            <a target="_blank" href="https://hpcs.snu.ac.kr/~jangwoo/">Jangwoo Kim</a> on computer architectures, and
            with Prof.
             <a target="_blank" href="https://spl.snu.ac.kr/">Byung-Gon Chun</a> on deep learning software systems.
            </p>
          <div><p class="text"></p></div>
          <div><p class="text"></p></div>
          </div>
        </div>
        <!--End About-->
        <!-------------------------------------------------------------------------------------------->


        <!--Start Selected Publication-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Selected Publications</h2>
            <hr>
            <p class="text">
            <a href="#publications">Click to view the full list of publications. </a>
            </p>

            <!--Start Selected Publication List-->
            <div id="publications-container"></div>
            <!--End Selected Publication List-->
          </div>

        </div>
        <!--End Selected Publication-->
        <!-------------------------------------------------------------------------------------------->
        <!--Start Publication-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin" id="publications">Publications</h2>
            <hr>

        			<!--Start Publication List-->
							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2403.15042.pdf">
								<b>LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement</b></a>
								<a href="https://github.com/SqueezeAILab/LLM2LLM">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                Nicholas Lee*, Thanakul Wattanawong*, <b>Sehoon Kim</b>, Karttikeya Mangalam, Sheng Shen, Gopala Anumanchipali, Michael W Mahoney, Kurt Keutzer, Amir Gholami<br>
              	<i>Preprint, 2024</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2401.18079.pdf">
								<b>KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization</b></a>
								<a href="https://github.com/SqueezeAILab/KVQuant">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                Coleman Hooper, <b>Sehoon Kim</B>, Hiva Mohammadzadeh, Michael W Mahoney, Yakun Sophia Shao, Kurt Keutzer, Amir Gholami<br>
              	<i>Preprint, 2024</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2401.07886.pdf">
								<b>Learned Best-Effort LLM Serving</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                Siddharth Jha, Coleman Hooper, Xiaoxuan Liu, <b>Sehoon Kim</b>, Kurt Keutzer<br>
              	<i>Preprint, 2024</i>
            	</p>


							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2312.04511.pdf">
								<b>An LLM Compiler for Parallel Function Calling</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                <b>Sehoon Kim*</b>, Suhong Moon*, Ryan Tabrizi, Nicholas Lee, Michael W. Mahoney, Kurt Keutzer, Amir Gholami<br>
              	<i>Preprint, 2023</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2310.12072.pdf">
								<b>SPEED: Speculative Pipelined Execution for Efficient Decoding</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                Coleman Hooper, <b>Sehoon Kim</b>, Hiva Mohammadzadeh, Hasan Genc, Kurt Keutzer, Amir Gholami, Sophia Shao<br>
              	<i>NeurIPS Workshop on Efficient Natural Language and Speech Processing, 2023</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2306.07629.pdf">
								<b>SqueezeLLM: Dense-and-Sparse Quantization</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                <b>Sehoon Kim*</b>, Coleman Hooper*, Amir Gholami*, Zhen Dong, Xiuyu Li, Sheng Shen, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>Preprint, 2023 (Short Version at ISCA ASSYST Workshop 2023)</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2302.14017.pdf">
								<b>Full Stack Optimization of Transformer Inference: a Survey</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                <b>Sehoon Kim*</b>, Coleman Hooper*, Thanakul Wattanawong, Minwoo Kang, Ruohan Yan, Hasan Genc, Grace Dinh, Qijing Huang, Kurt Keutzer, Michael W. Mahoney, Yakun Sophia Shao, Amir Gholami<br>
              	<i>Preprint, 2023</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2302.07863.pdf">
								<b>Speculative Decoding with Big Little Decoder</b></a>
								<a href="https://github.com/kssteven418/BigLittleDecoder">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                <b>Sehoon Kim</b>, Karttikeya Mangalam, Suhong Moon, Jitendra Malik, Michael W. Mahoney, Amir Gholami, Kurt Keutzer<br>
              	<i>Conference on Neural Information Processing Systems (NeurIPS), 2023</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2206.00888.pdf">
								<b>Squeezeformer: An Efficient Transformer for Automatic Speech Recognition</b></a>
								<a href="https://github.com/kssteven418/Squeezeformer">[code]</a>
                  <a href="https://catalog.ngc.nvidia.com/models?filters=&orderBy=weightPopularDESC&query=squeezeformer">[NeMo official]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                <b>Sehoon Kim*</b>, Amir Gholami*, Albert Shaw†, Nicholas Lee†,
                Karttikeya Mangalam, Jitendra Malik, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>Conference on Neural Information Processing Systems (NeurIPS), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2204.09656.pdf">
								<b>A Fast Post-Training Pruning Framework for Transformers</b></a>
								<a href="https://github.com/WoosukKwon/retraining-free-pruning">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Woosuk Kwon*, <b>Sehoon Kim*</b>, Michael W. Mahoney, Joseph Hassoun, Kurt Keutzer, Amir Gholami<br>
              	<i>Conference on Neural Information Processing Systems (NeurIPS), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2107.00910.pdf">
								<b>Learned Token Pruning for Transformers</b></a>
								<a href="https://github.com/kssteven418/LTP">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	<b>Sehoon Kim*</b>, Sheng Shen*, David Thorsley*, Amir Gholami*, Woosuk Kwon, Joseph Hassoun, Kurt Keutzer<br>
              	<i>Conference on Knowledge Discovery and Data Mining (KDD), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2103.16827.pdf">
								<b>Integer-only Zero-shot Quantization for Efficient Speech Recognition</b></a>
								<a href="https://github.com/kssteven418/Q-ASR">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	<b>Sehoon Kim</b>, Amir Gholami, Zhewei Yao, Nicholas Lee, Patrick Wang, Anirudda Nrusimha, Bohan Zhai,
								Tianren Gao, Michael W. Mahoney, Kurt Keutzer,<br>
              	<i>International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://openaccess.thecvf.com/content/WACV2022/papers/Yu_Hessian-Aware_Pruning_and_Optimal_Neural_Implant_WACV_2022_paper.pdf">
								<b>Hessian-Aware Pruning and Optimal Neural Implant</b></a>
								<a href="https://github.com/yaozhewei/HAP">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Shixing Yu*, Zhewei Yao*, Amir Gholami*, Zhen Dong*, <b>Sehoon Kim</b>, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>Winter Conference on Applications of Computer Vision (WACV), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2103.13630.pdf">
								<b>A Survey of Quantization Methods for Efficient Neural Network Inference</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Amir Gholami*, <b>Sehoon Kim*</b>, Zhen Dong*, Zhewei Yao*, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>Book Chapter: Low-Power Computer Vision: Improving the Efficiency of Artificial Intelligence, 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://www.vldb.org/pvldb/vol15/p11-yu.pdf">
								<b>WindTunnel: Towards Differentiable ML Pipelines Beyond a Single Model</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Gyeong-In Yu, Saeed Amizadeh, <b>Sehoon Kim</b>, Artidoro Pagnoni, Ce Zhang, Byung-Gon Chun, Markus Weimer, Matteo Interlandi<br>
              	<i>International Conference on Very Large Data Bases (VLDB), 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://proceedings.neurips.cc/paper/2021/file/0b32f1a9efe5edf3dd2f38b0c0052bfe-Paper.pdf">
								<b>Terra: Imperative-Symbolic Co-Execution of Imperative Deep Learning Programs</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Taebum Kim, Eunji Jeong, Geon-Woo Kim, Yunmo Koo, <b>Sehoon Kim</b>, Gyeong-In Yu, Byung-Gon Chun<br>
              	<i>Conference on Neural Information Processing Systems (NeurIPS), 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="http://proceedings.mlr.press/v139/kim21d/kim21d.pdf">
								<b>I-BERT: Integer-only BERT Quantization </b></a>
								<a href="https://github.com/kssteven418/I-BERT">[code]</a>
								<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/ibert">[HF official]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	<b>Sehoon Kim*</b>, Amir Gholami*, Zhewei Yao*, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>International Conference on Machine Learning (ICML, <b>Oral</b>), 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="publications/xu2021-ispass.pdf">
								<b>Memory-Efficient Hardware Performance Counters with Approximate-Counting Algorithms</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Jingyi Xu, <b>Sehoon Kim</b>, Borivoje Nikolic, Yakun Sophia Shao<br>
              	<i>International Symposium on Performance Analysis of Systems and Software (ISPASS), 2021</i>
            	</p>

        			<!--End Publication List-->
          </div>
        </div>
        <!--End Publication-->
      </div>
    </div>
  </div>
<script src="js/selected_publications.js"></script>
</body>

</html>

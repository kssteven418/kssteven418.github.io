<!doctype html>
<html>

<head>
  <!--<meta name="google-site-verification" content="-7Nk1zZNdUpUv3uY4z2NdOnsrV0IaNwzgVfoPZtGYvg" />-->
  <meta name="google-site-verification" content="tJrbM3Uji0UXppLjVTvNHyTlh_L4u_mUV3ysGOWN2Gg" />
  <title>Sehoon Kim</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="index, follow" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!-------------------------------------------------------------------------------------------->
        <!--Start Intro-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" src="img/main.jpg" width="200" height="257">
          </div>
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Sehoon Kim</h2>
            <p class="text text-medium">
              Ph.D. Student in
              <a target="_blank" href="https://bair.berkeley.edu/">BAIR</a> 
              at <a target="_blank" href="https://eecs.berkeley.edu/">UC Berkeley</a><br>
              <b>Contact:</b> sehoonkim at berkeley dot edu <br>
              <b>CV:</b> <a target="_blank" href="files/CV_sehoonkim.pdf">link</a> (latest update: Sep. 2022)<br>
              <b>Advisor:</b> Prof. <a target="_blank" href="http://people.eecs.berkeley.edu/~keutzer/">Kurt Keutzer</a><br>
              <b>Research Interests:</b> 
              Efficient AI, HW-SW Codesign, AI Systems<br>
            </p>

            </p>
          </div>
        </div>
        </div>
        <!--End Intro-->
        <!-------------------------------------------------------------------------------------------->
        <!--Start About-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">About</h2>
            <hr>
            <p class="text">
            I am a 3rd year Ph.D. student in 
             <a target="_blank" href="https://bair.berkeley.edu/">Berkeley AI Research (BAIR)</a>
             at  <a target="_blank" href="https://eecs.berkeley.edu/">EECS, UC Berkeley</a>.
            I am working on a wide rage of <b>full-stack approaches for efficient AI and deep learning</b> under the supervision of Prof.
            <a target="_blank" href="http://people.eecs.berkeley.edu/~keutzer/">Kurt Keutzer</a>.
            More specifically, my research interests lie in:
            <ul style="margin : 0; padding-top:0; margin-bottom:0;">
              <li>Efficient algorithms and model compression techniques for low-cost deep learning inference at the edge</li>
              <li>Efficient model architecture design and hardware-aware neural architecture search (NAS)</li>
              <li>Hardware-software co-design and co-optimization</li>
              <li>AI systems for efficient model training and inference</li>
            </ul>  
            </p>

            <p class="text" style="margin : 0; padding-top:0;">
            Before joining UC Berkeley, I was an undergrad majoring in 
            <a target="_blank" href="https://ee.snu.ac.kr/en">Electrical and Computer Engineering (ECE)</a> at 
            <a target="_blank" href="https://en.snu.ac.kr/">Seoul National University</a>, 
            where I was ranked <b>1st in the entire class</b> of 2020 (overall GPA: 4.29/4.30, major GPA: 4.30/4.30).
            In my undergrad years, I was honored to work with Prof.
            <a target="_blank" href="https://hpcs.snu.ac.kr/~jangwoo/">Jangwoo Kim</a> on computer architectures, and 
            with Prof.
             <a target="_blank" href="https://spl.snu.ac.kr/">Byung-Gon Chun</a> on deep learning software systems.
            </p>
            <!--
            <p class="text">
              Ma quande lingues coalesce, li grammatica del resultant lingue es plu simplic e regulari quam ti del
              coalescent lingues. Li nov lingua franca va esser plu simplic e regulari quam li existent Europan lingues.
            </p>
            -->
          <div><p class="text"></p></div>
          <div><p class="text"></p></div>
          </div>
        </div>
        <!--End About-->
        <!-------------------------------------------------------------------------------------------->
        <!--Start Selected Publication-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Selected Publications</h2>
            <hr>
            <p class="text"> 
            <a href="#publications">Click to view the full list of publications. </a>
            </p>

            <!--Start Selected Publication List-->
            <div class="flex-row">
              <div class="flex-item flex-item-stretch flex-column">
                <img class="image max-width-500" src="img/thumbnails/sqfm.png">
              </div>
              <div class="flex-item flex-item-stretch-4 flex-column">
                <p class="text-large" style="margin-bottom:0;">
              	  <a href="https://arxiv.org/pdf/2206.00888.pdf">
								  <b>Squeezeformer: An Efficient Transformer for Automatic Speech Recognition</b></a>
								  <a href="https://github.com/kssteven418/Squeezeformer">[code]</a>
                  <a href="https://catalog.ngc.nvidia.com/models?filters=&orderBy=weightPopularDESC&query=squeezeformer">[NeMo official]</a>
                </p>
                <p class="text" style="margin : 0; padding-top:0;">
                  <b>Sehoon Kim*</b>, Amir Gholami*, Albert Shaw†, Nicholas Lee†, 
                  Karttikeya Mangalam, Jitendra Malik, Michael W. Mahoney, Kurt Keutzer<br>
                  <i>Conference on Neural Information Processing Systems (NeurIPS, to appear), 2022</i><br>
                  A next-generation attention-convolution hybrid architecture for efficient Automatic Speech Recognition
                </p>
              </div>

            <div class="flex-row">
              <div class="flex-item flex-item-stretch flex-column">
                <img class="image max-width-500" src="img/thumbnails/ptp.png">
              </div>
              <div class="flex-item flex-item-stretch-4 flex-column">
                <p class="text-large" style="margin-bottom:0;">
                  <a href="https://arxiv.org/pdf/2204.09656.pdf">
                  <b>A Fast Post-Training Pruning Framework for Transformers</b></a>
                  <a href="https://github.com/WoosukKwon/retraining-free-pruning">[code]</a>
                </p>
                <p class="text" style="margin : 0; padding-top:0;">
                  Woosuk Kwon*, <b>Sehoon Kim*</b>, Michael W. Mahoney, Joseph Hassoun, Kurt Keutzer, Amir Gholami<br>
                  <i>Conference on Neural Information Processing Systems (NeurIPS, to appear), 2022</i><br>
                  Fast post-training pruning method for Transformers that searches for accurate and structured 
                  sparsity patterns without retraining
                </p>
              </div>

            <div class="flex-row">
              <div class="flex-item flex-item-stretch flex-column">
                <img class="image max-width-500" src="img/thumbnails/ltp.png">
              </div>
              <div class="flex-item flex-item-stretch-4 flex-column">
                <p class="text-large" style="margin-bottom:0;">
                  <a href="https://arxiv.org/pdf/2107.00910.pdf">
                  <b>Learned Token Pruning for Transformers</b></a>
                  <a href="https://github.com/kssteven418/LTP">[code]</a>
                </p>
                <p class="text" style="margin : 0; padding-top:0;">
                  <b>Sehoon Kim*</b>, Sheng Shen*, David Thorsley*, Amir Gholami*, Woosuk Kwon, Joseph Hassoun, Kurt Keutzer<br>
                  <i>Conference on Knowledge Discovery and Data Mining (KDD), 2022</i><br>
                  Token pruning scheme for Transformers that detects and drops less important tokens for efficient inference 
                </p>
              </div>
            </div>
          <div><p class="text"></p></div>
          <div><p class="text"></p></div>


            <div class="flex-row">
              <div class="flex-item flex-item-stretch flex-column">
                <img class="image max-width-500" src="img/thumbnails/q-asr.png">
              </div>
              <div class="flex-item flex-item-stretch-4 flex-column">
                <p class="text-large" style="margin-bottom:0;">
                  <a href="https://arxiv.org/pdf/2103.16827.pdf">
                  <b>Integer-only Zero-shot Quantization for Efficient Speech Recognition</b></a>
                  <a href="https://github.com/kssteven418/Q-ASR">[code]</a>
                </p>
                <p class="text" style="margin : 0; padding-top:0;">
                  <b>Sehoon Kim</b>, Amir Gholami, Zhewei Yao, Nicholas Lee, Patrick Wang, Anirudda Nrusimha, Bohan Zhai,
                  Tianren Gao, Michael W. Mahoney, Kurt Keutzer,<br>
                  <i>International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2022</i><br>
                  Integer-only quantization scheme for ASR models that does not require any training/validation data
                </p>
              </div>
            </div>
          <div><p class="text"></p></div>
          <div><p class="text"></p></div>


            <div class="flex-row">
              <div class="flex-item flex-item-stretch flex-column">
                <img class="image max-width-500" src="img/thumbnails/i-bert.png">
              </div>
              <div class="flex-item flex-item-stretch-4 flex-column">
                <p class="text-large" style="margin-bottom:0;">
                  <a href="http://proceedings.mlr.press/v139/kim21d/kim21d.pdf">
                  <b>I-BERT: Integer-only BERT Quantization </b></a>
                  <a href="https://github.com/kssteven418/I-BERT">[code]</a>
                  <a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/ibert">[HF official]</a>
                </p>
                <p class="text" style="margin : 0; padding-top:0;">
                  <b>Sehoon Kim*</b>, Amir Gholami*, Zhewei Yao*, Michael W. Mahoney, Kurt Keutzer<br>
                  <i>International Conference on Machine Learning (ICML, <b>Long talk</b>), 2021</i><br>
                  Integer-only quantization scheme for Transformers that performs entire inference with integer arithmetic
                </p>
              </div>
          <div><p class="text"></p></div>
          <div><p class="text"></p></div>

            <!--End Selected Publication List-->

          </div>
          <div><p class="text"></p></div>
          <div><p class="text"></p></div>
        </div>
        <!--End Selected Publication-->
        <!-------------------------------------------------------------------------------------------->
        <!--Start Publication-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin" id="publications">Publications</h2>
            <hr>

        			<!--Start Publication List-->
							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2206.00888.pdf">
								<b>Squeezeformer: An Efficient Transformer for Automatic Speech Recognition</b></a>
								<a href="https://github.com/kssteven418/Squeezeformer">[code]</a>
                  <a href="https://catalog.ngc.nvidia.com/models?filters=&orderBy=weightPopularDESC&query=squeezeformer">[NeMo official]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
                <b>Sehoon Kim*</b>, Amir Gholami*, Albert Shaw†, Nicholas Lee†, 
                Karttikeya Mangalam, Jitendra Malik, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>Conference on Neural Information Processing Systems (NeurIPS, to appear), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2204.09656.pdf">
								<b>A Fast Post-Training Pruning Framework for Transformers</b></a>
								<a href="https://github.com/WoosukKwon/retraining-free-pruning">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Woosuk Kwon*, <b>Sehoon Kim*</b>, Michael W. Mahoney, Joseph Hassoun, Kurt Keutzer, Amir Gholami<br>
              	<i>Conference on Neural Information Processing Systems (NeurIPS, to appear), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2107.00910.pdf">
								<b>Learned Token Pruning for Transformers</b></a>
								<a href="https://github.com/kssteven418/LTP">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	<b>Sehoon Kim*</b>, Sheng Shen*, David Thorsley*, Amir Gholami*, Woosuk Kwon, Joseph Hassoun, Kurt Keutzer<br>
              	<i>Conference on Knowledge Discovery and Data Mining (KDD), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2103.16827.pdf">
								<b>Integer-only Zero-shot Quantization for Efficient Speech Recognition</b></a>
								<a href="https://github.com/kssteven418/Q-ASR">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	<b>Sehoon Kim</b>, Amir Gholami, Zhewei Yao, Nicholas Lee, Patrick Wang, Anirudda Nrusimha, Bohan Zhai,
								Tianren Gao, Michael W. Mahoney, Kurt Keutzer,<br>
              	<i>International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://openaccess.thecvf.com/content/WACV2022/papers/Yu_Hessian-Aware_Pruning_and_Optimal_Neural_Implant_WACV_2022_paper.pdf">
								<b>Hessian-Aware Pruning and Optimal Neural Implant</b></a>
								<a href="https://github.com/yaozhewei/HAP">[code]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Shixing Yu*, Zhewei Yao*, Amir Gholami*, Zhen Dong*, <b>Sehoon Kim</b>, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>Winter Conference on Applications of Computer Vision (WACV), 2022</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://arxiv.org/pdf/2103.13630.pdf">
								<b>A Survey of Quantization Methods for Efficient Neural Network Inference</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Amir Gholami*, <b>Sehoon Kim*</b>, Zhen Dong*, Zhewei Yao*, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>Book Chapter: Low-Power Computer Vision: Improving the Efficiency of Artificial Intelligence, 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://www.vldb.org/pvldb/vol15/p11-yu.pdf">
								<b>WindTunnel: Towards Differentiable ML Pipelines Beyond a Single Model</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Gyeong-In Yu, Saeed Amizadeh, <b>Sehoon Kim</b>, Artidoro Pagnoni, Ce Zhang, Byung-Gon Chun, Markus Weimer, Matteo Interlandi<br>
              	<i>International Conference on Very Large Data Bases (VLDB), 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="https://proceedings.neurips.cc/paper/2021/file/0b32f1a9efe5edf3dd2f38b0c0052bfe-Paper.pdf">
								<b>Terra: Imperative-Symbolic Co-Execution of Imperative Deep Learning Programs</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Taebum Kim, Eunji Jeong, Geon-Woo Kim, Yunmo Koo, <b>Sehoon Kim</b>, Gyeong-In Yu, Byung-Gon Chun<br>
              	<i>Conference on Neural Information Processing Systems (NeurIPS), 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="http://proceedings.mlr.press/v139/kim21d/kim21d.pdf">
								<b>I-BERT: Integer-only BERT Quantization </b></a>
								<a href="https://github.com/kssteven418/I-BERT">[code]</a>
								<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/ibert">[HF official]</a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	<b>Sehoon Kim*</b>, Amir Gholami*, Zhewei Yao*, Michael W. Mahoney, Kurt Keutzer<br>
              	<i>International Conference on Machine Learning (ICML, <b>Long talk</b>), 2021</i>
            	</p>

							<p class="text-large" style="margin-bottom:0;">
              	<a href="publications/xu2021-ispass.pdf">
								<b>Memory-Efficient Hardware Performance Counters with Approximate-Counting Algorithms</b></a>
							</p>
							<p class="text" style="margin : 0; padding-top:0;">
              	Jingyi Xu, <b>Sehoon Kim</b>, Borivoje Nikolic, Yakun Sophia Shao<br>
              	<i>International Symposium on Performance Analysis of Systems and Software (ISPASS), 2021</i>
            	</p>
							
        			<!--End Publication List-->
          </div>
        </div>
        <!--End Publication-->
      </div>
    </div>
  </div>
</body>

</html>
